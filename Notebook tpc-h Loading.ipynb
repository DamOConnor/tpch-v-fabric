{"nbformat":4,"nbformat_minor":5,"metadata":{"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"host":{"synapse_widget":{"token":"222f3f30-da85-4617-8c99-1702c8b3c280","state":{}}}},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"trident":{"lakehouse":{"known_lakehouses":[{"id":"a5227207-9429-41d0-9d40-cdaffa4e7a95"}],"default_lakehouse":"a5227207-9429-41d0-9d40-cdaffa4e7a95","default_lakehouse_name":"lh_tpch1","default_lakehouse_workspace_id":"42f6cbc9-8941-4e6c-94a9-666750486ba6"}}},"cells":[{"cell_type":"markdown","source":["# tpc-h Loading\n","\n","Load tpc-h data from pipe-separated files stored in ADLS Gen 2 into a Lakehouse in Fabric.\n","\n","Approximate run times for scale:  \n","1: ~1 min  \n","10: ~3 mins  \n","100: ~7 mins  \n","1000: ~43 mins  \n","\n","**Agenda**  \n","Intro to Notebooks; language; startup time; markdown; table of contents; parameters; magics; frozen cell; parallel run; charting;  \n","variables; shortcuts; notebook resources; refresh table view; max workers; struct; dictionary; schema datatypes  \n","collaboration; Settings: About; change name; endorsement; scheduling, open in VS Code"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d69b7356-47d1-446a-8196-54938228a502"},{"cell_type":"markdown","source":["## Setup"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4ceb3abc-4fb5-4b86-8889-38d9e4ae9509"},{"cell_type":"markdown","source":["### Parameters\n","file_path - the path to the tpch files to be loaded into the lakehouse\n","\n","Examples:  \n","Local files: \"Files/scale 1\"  \n","Shortcut files: \"Files/tpch csv/scale 100\""],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"4959aac3-bf4d-4d13-86c2-d9028b24465b"},{"cell_type":"code","source":["file_path = \"Files/tpch1 (1)/raw/tpc-h/scale1/csv\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"e4252176-7253-4989-8af2-efcc9bc414e0","statement_id":35,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-29T20:41:19.9109322Z","session_start_time":null,"execution_start_time":"2023-09-29T20:41:20.2404494Z","execution_finish_time":"2023-09-29T20:41:20.5567403Z","spark_jobs":{"numbers":{"FAILED":0,"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"63e5e60b-2070-4f5b-bf2e-b6cad196971c"},"text/plain":"StatementMeta(, e4252176-7253-4989-8af2-efcc9bc414e0, 35, Finished, Available)"},"metadata":{}}],"execution_count":19,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]},"id":"acb2ab0a-7880-48c7-9056-787a519f7930"},{"cell_type":"markdown","source":["### Imports\n","Define any imports that will be used in the notebook"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"83a28302-8c23-4c73-b2ef-e906895be74a"},{"cell_type":"code","source":["from pyspark.sql.types import *"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"e4252176-7253-4989-8af2-efcc9bc414e0","statement_id":36,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-29T20:41:19.9984955Z","session_start_time":null,"execution_start_time":"2023-09-29T20:41:21.0583485Z","execution_finish_time":"2023-09-29T20:41:21.3682251Z","spark_jobs":{"numbers":{"FAILED":0,"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"9894315c-e5de-47f2-aca8-e44789db2b8d"},"text/plain":"StatementMeta(, e4252176-7253-4989-8af2-efcc9bc414e0, 36, Finished, Available)"},"metadata":{}}],"execution_count":20,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"83215cdd-d247-480a-a437-174b6e71b9f8"},{"cell_type":"markdown","source":["### Functions\n","Define the functions that will be used in the notebook"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"80a75aa6-5450-41d2-b17b-fa21b56eb136"},{"cell_type":"code","source":["# This function gets the pipe-separated text files, loads them to a dataframe with the input schema and then loads to a lakehouse table\n","def get_and_load_tpch_file(file_path, table_name, schema):\n","    df = spark.read.option(\"sep\", \"|\").csv(f\"{file_path}/{table_name}.tbl\", header=False, schema=schema)\n","    df.write.mode(\"overwrite\").format(\"delta\").save(\"Tables/\" + table_name)\n","\n","\n","# Get the pipe-separated text file load to a dataframe with the given schema and return that dataframe\n","def get_tpch_file(file_path, table_name, schema):\n","    df = spark.read.option(\"sep\", \"|\").csv(f\"{file_path}/{table_name}.tbl\", header=False, schema=schema)\n","    return df\n","\n","\n","# Save the input dataframe as a delta table in the lakehouse\n","def save_tpch_file(df, table_name):\n","    df.write.mode(\"overwrite\").format(\"delta\").save(\"Tables/\" + table_name)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"e4252176-7253-4989-8af2-efcc9bc414e0","statement_id":37,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-29T20:41:20.1047107Z","session_start_time":null,"execution_start_time":"2023-09-29T20:41:21.8297269Z","execution_finish_time":"2023-09-29T20:41:22.1246601Z","spark_jobs":{"numbers":{"FAILED":0,"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"c027eb93-8449-49dc-9d46-efee326cfee1"},"text/plain":"StatementMeta(, e4252176-7253-4989-8af2-efcc9bc414e0, 37, Finished, Available)"},"metadata":{}}],"execution_count":21,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"55f78f78-952d-4ed0-9023-b2691fdaf597"},{"cell_type":"markdown","source":["### Reset\n","Delete all tables from the database"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"82dbc856-d431-470c-b973-5ea539b88b7b"},{"cell_type":"code","source":["%%sql\n","DROP TABLE IF EXISTS customer;\n","DROP TABLE IF EXISTS lineitem;\n","DROP TABLE IF EXISTS nation;\n","DROP TABLE IF EXISTS orders;\n","DROP TABLE IF EXISTS part;\n","DROP TABLE IF EXISTS partsupp;\n","DROP TABLE IF EXISTS region;\n","DROP TABLE IF EXISTS supplier;"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"e4252176-7253-4989-8af2-efcc9bc414e0","statement_id":-1,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-29T20:41:20.2045864Z","session_start_time":null,"execution_start_time":"2023-09-29T20:41:34.4138001Z","execution_finish_time":"2023-09-29T20:41:34.4140516Z","spark_jobs":{"numbers":{"FAILED":0,"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"9556902c-8dd3-4cf3-844d-fb46cac0a7bc"},"text/plain":"StatementMeta(, e4252176-7253-4989-8af2-efcc9bc414e0, -1, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":22,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}},{"output_type":"execute_result","execution_count":22,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}},{"output_type":"execute_result","execution_count":22,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}},{"output_type":"execute_result","execution_count":22,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}},{"output_type":"execute_result","execution_count":22,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}},{"output_type":"execute_result","execution_count":22,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}},{"output_type":"execute_result","execution_count":22,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}},{"output_type":"execute_result","execution_count":22,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[]},"data":[]},"text/plain":"<Spark SQL result set with 0 rows and 0 fields>"},"metadata":{}}],"execution_count":22,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"02bcb0a8-2d3e-4d69-98ed-dec310c33a87"},{"cell_type":"markdown","source":["### Schemas\n","  Define the schemas for all tables to be imported.  \n","This code is using a dictionary to hold the table name and table schema.\n","\n","5.5 Dictionaries  \n","https://docs.python.org/3/tutorial/datastructures.html\n","\n","Dictionaries are similar to arrays, but contain key:value pairs, where keys must be unique within that dictionary.\n","This dictionary (dict_schemas) holds the table name (key) and a struct containing the schema, including column name, datatype and nullability."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f9bbfaa8-e986-4bf5-9955-a9cf8b066e66"},{"cell_type":"code","source":["# Create a dictionary holding the table name and accompanying schema\n","dict_schemas = {\n","    'customer': StructType([\n","        StructField(\"custkey\", IntegerType(), nullable=False),\n","        StructField(\"name\", StringType(), nullable=False),\n","        StructField(\"address\", StringType(), nullable=False),\n","        StructField(\"nationkey\", IntegerType(), nullable=True),\n","        StructField(\"phone\", StringType(), nullable=True),\n","        StructField(\"acctbal\", FloatType(), nullable=True),\n","        StructField(\"mktsegment\", StringType(), nullable=True),\n","        StructField(\"comment\", StringType(), nullable=True)\n"," ]),\n","    'lineitem': StructType([\n","        StructField(\"orderkey\", IntegerType(), nullable=False),\n","        StructField(\"partkey\", IntegerType(), nullable=False),\n","        StructField(\"suppkey\", IntegerType(), nullable=False),\n","        StructField(\"linenumber\", IntegerType(), nullable=False),\n","        StructField(\"quantity\", FloatType(), nullable=True),\n","        StructField(\"extendedprice\", FloatType(), nullable=True),\n","        StructField(\"discount\", FloatType(), nullable=True),\n","        StructField(\"tax\", FloatType(), nullable=True),\n","        StructField(\"returnflag\", StringType(), nullable=False),\n","        StructField(\"linestatus\", StringType(), nullable=False),\n","        StructField(\"shipdate\", DateType(), nullable=False),\n","        StructField(\"commitdate\", DateType(), nullable=False),\n","        StructField(\"receiptdate\", DateType(), nullable=False),\n","        StructField(\"shipinstruct\", StringType(), nullable=False),\n","        StructField(\"shipmode\", StringType(), nullable=False),\n","        StructField(\"comment\", StringType(), nullable=True)\n","    ]),\n","    'nation': StructType([\n","        StructField(\"nationkey\", IntegerType(), nullable=False),\n","        StructField(\"name\", StringType(), nullable=False),\n","        StructField(\"regionkey\", IntegerType(), nullable=False),\n","        StructField(\"comment\", StringType(), nullable=True)\n","    ]),\n","    'orders': StructType([\n","        StructField(\"orderkey\", IntegerType(), nullable=False),\n","        StructField(\"custkey\", IntegerType(), nullable=False),\n","        StructField(\"orderstatus\", StringType(), nullable=False),\n","        StructField(\"totalprice\", FloatType(), nullable=True),\n","        StructField(\"orderdate\", DateType(), nullable=False),\n","        StructField(\"orderpriority\", StringType(), nullable=False),\n","        StructField(\"clearkdate\", StringType(), nullable=False),\n","        StructField(\"shippriority\", IntegerType(), nullable=False),\n","        StructField(\"comment\", StringType(), nullable=True)\n","    ]),\n","    'part': StructType([\n","        StructField(\"partkey\", IntegerType(), nullable=False),\n","        StructField(\"name\", StringType(), nullable=True),\n","        StructField(\"mfgr\", StringType(), nullable=True),\n","        StructField(\"brand\", StringType(), nullable=True),\n","        StructField(\"type\", StringType(), nullable=True),\n","        StructField(\"size\", IntegerType(), nullable=True),\n","        StructField(\"container\", StringType(), nullable=True),\n","        StructField(\"retailprice\", FloatType(), nullable=True),\n","        StructField(\"comment\", StringType(), nullable=True)\n","    ]),\n","    'partsupp': StructType([\n","        StructField(\"partkey\", IntegerType(), nullable=False),\n","        StructField(\"suppkey\", IntegerType(), nullable=False),\n","        StructField(\"availqty\", IntegerType(), nullable=False),\n","        StructField(\"supplycost\", FloatType(), nullable=True),\n","        StructField(\"comment\", StringType(), nullable=True)\n","    ]),\n","    'region': StructType([\n","        StructField(\"regionkey\", StringType(), nullable=False),\n","        StructField(\"name\", StringType(), nullable=False),\n","        StructField(\"comment\", StringType(), nullable=True)\n","    ]),\n","    'supplier': StructType([\n","        StructField(\"suppkey\", IntegerType(), nullable=False),\n","        StructField(\"name\", StringType(), nullable=False),\n","        StructField(\"address\", StringType(), nullable=False),\n","        StructField(\"nationkey\", IntegerType(), nullable=True),\n","        StructField(\"phone\", StringType(), nullable=True),\n","        StructField(\"acctbal\", FloatType(), nullable=True),\n","        StructField(\"comment\", StringType(), nullable=True)\n","    ])\n","}\n","\n","\n","for table_name, schema in dict_schemas.items():\n","    print(table_name, '\\r\\n', schema, '\\r\\n')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"e4252176-7253-4989-8af2-efcc9bc414e0","statement_id":46,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-29T20:41:20.3024743Z","session_start_time":null,"execution_start_time":"2023-09-29T20:41:34.8258188Z","execution_finish_time":"2023-09-29T20:41:35.1219161Z","spark_jobs":{"numbers":{"FAILED":0,"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"774da4d9-ec4d-4439-a582-9deedf7e2801"},"text/plain":"StatementMeta(, e4252176-7253-4989-8af2-efcc9bc414e0, 46, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["customer \r\n StructType([StructField('custkey', IntegerType(), False), StructField('name', StringType(), False), StructField('address', StringType(), False), StructField('nationkey', IntegerType(), True), StructField('phone', StringType(), True), StructField('acctbal', FloatType(), True), StructField('mktsegment', StringType(), True), StructField('comment', StringType(), True)]) \r\n\nlineitem \r\n StructType([StructField('orderkey', IntegerType(), False), StructField('partkey', IntegerType(), False), StructField('suppkey', IntegerType(), False), StructField('linenumber', IntegerType(), False), StructField('quantity', FloatType(), True), StructField('extendedprice', FloatType(), True), StructField('discount', FloatType(), True), StructField('tax', FloatType(), True), StructField('returnflag', StringType(), False), StructField('linestatus', StringType(), False), StructField('shipdate', DateType(), False), StructField('commitdate', DateType(), False), StructField('receiptdate', DateType(), False), StructField('shipinstruct', StringType(), False), StructField('shipmode', StringType(), False), StructField('comment', StringType(), True)]) \r\n\nnation \r\n StructType([StructField('nationkey', IntegerType(), False), StructField('name', StringType(), False), StructField('regionkey', IntegerType(), False), StructField('comment', StringType(), True)]) \r\n\norders \r\n StructType([StructField('orderkey', IntegerType(), False), StructField('custkey', IntegerType(), False), StructField('orderstatus', StringType(), False), StructField('totalprice', FloatType(), True), StructField('orderdate', DateType(), False), StructField('orderpriority', StringType(), False), StructField('clearkdate', StringType(), False), StructField('shippriority', IntegerType(), False), StructField('comment', StringType(), True)]) \r\n\npart \r\n StructType([StructField('partkey', IntegerType(), False), StructField('name', StringType(), True), StructField('mfgr', StringType(), True), StructField('brand', StringType(), True), StructField('type', StringType(), True), StructField('size', IntegerType(), True), StructField('container', StringType(), True), StructField('retailprice', FloatType(), True), StructField('comment', StringType(), True)]) \r\n\npartsupp \r\n StructType([StructField('partkey', IntegerType(), False), StructField('suppkey', IntegerType(), False), StructField('availqty', IntegerType(), False), StructField('supplycost', FloatType(), True), StructField('comment', StringType(), True)]) \r\n\nregion \r\n StructType([StructField('regionkey', StringType(), False), StructField('name', StringType(), False), StructField('comment', StringType(), True)]) \r\n\nsupplier \r\n StructType([StructField('suppkey', IntegerType(), False), StructField('name', StringType(), False), StructField('address', StringType(), False), StructField('nationkey', IntegerType(), True), StructField('phone', StringType(), True), StructField('acctbal', FloatType(), True), StructField('comment', StringType(), True)]) \r\n\n"]}],"execution_count":23,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"5854c2a7-91a1-45e5-a21d-b5a9fd0b2378"},{"cell_type":"markdown","source":["## Main\n","Load all the tables into the database"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f6603fb9-8d95-48f6-89a6-2f50033e4e07"},{"cell_type":"markdown","source":["### Serial load"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2d9726cf-2abc-4152-806d-1ce63446d693"},{"cell_type":"code","source":["for table_name, schema in dict_schemas.items():\n","    print(table_name, '\\r\\n', schema, '\\r\\n')\n","    get_and_load_tpch_file(file_path, table_name, schema)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"editable":false,"run_control":{"frozen":true}},"id":"2f6dd04f-0bb1-4cfc-8a43-563d28b65adc"},{"cell_type":"markdown","source":["### Parallel load\n","Use concurrent.futures to loop through the schema dictionary in parallel"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"49f2d87a-9162-4573-ad2e-9f8293976f8c"},{"cell_type":"code","source":["# Loop through the schemas dictionary in parallel\n","from concurrent.futures import ThreadPoolExecutor\n","\n","def load_table(table_name):\n","    schema = dict_schemas[table_name]\n","    get_and_load_tpch_file(file_path, table_name, schema)\n","\n","\n","# Use a ThreadPoolExecutor to run the tasks in parallel\n","with ThreadPoolExecutor(max_workers=4) as executor:\n","    executor.map(load_table, dict_schemas.keys())"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"e4252176-7253-4989-8af2-efcc9bc414e0","statement_id":47,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-29T20:41:20.4245855Z","session_start_time":null,"execution_start_time":"2023-09-29T20:41:35.5924878Z","execution_finish_time":"2023-09-29T20:42:20.8996202Z","spark_jobs":{"numbers":{"FAILED":0,"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":12},"jobs":[{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4373,"rowCount":50,"usageDescription":"","jobId":46,"name":"toString at String.java:2994","description":"Delta: Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys()): Compute snapshot for version: 0","submissionTime":"2023-09-29T20:42:05.962GMT","completionTime":"2023-09-29T20:42:06.042GMT","stageIds":[66,64,65],"jobGroup":"47","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":51,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4373,"dataRead":1632,"rowCount":54,"usageDescription":"","jobId":44,"name":"toString at String.java:2994","description":"Delta: Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys()): Compute snapshot for version: 0","submissionTime":"2023-09-29T20:42:04.934GMT","completionTime":"2023-09-29T20:42:05.933GMT","stageIds":[61,62],"jobGroup":"47","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":1632,"dataRead":1676,"rowCount":8,"usageDescription":"","jobId":42,"name":"toString at String.java:2994","description":"Delta: Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys()): Compute snapshot for version: 0","submissionTime":"2023-09-29T20:42:04.714GMT","completionTime":"2023-09-29T20:42:04.792GMT","stageIds":[60],"jobGroup":"47","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys())","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":38,"name":"","description":"Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys())","submissionTime":"2023-09-29T20:42:04.092GMT","completionTime":"2023-09-29T20:42:04.092GMT","stageIds":[],"jobGroup":"47","status":"SUCCEEDED","numTasks":0,"numActiveTasks":0,"numCompletedTasks":0,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":0,"numActiveStages":0,"numCompletedStages":0,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":43593216,"dataRead":57527587,"rowCount":1600000,"usageDescription":"","jobId":31,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys())","submissionTime":"2023-09-29T20:42:01.152GMT","completionTime":"2023-09-29T20:42:03.930GMT","stageIds":[42,43],"jobGroup":"47","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":57527587,"dataRead":120243368,"rowCount":1600000,"usageDescription":"","jobId":26,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys())","submissionTime":"2023-09-29T20:41:58.232GMT","completionTime":"2023-09-29T20:42:01.103GMT","stageIds":[39],"jobGroup":"47","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4403,"rowCount":50,"usageDescription":"","jobId":24,"name":"toString at String.java:2994","description":"Delta: Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys()): Compute snapshot for version: 0","submissionTime":"2023-09-29T20:41:57.220GMT","completionTime":"2023-09-29T20:41:57.882GMT","stageIds":[34,35,36],"jobGroup":"47","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":51,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4403,"dataRead":1821,"rowCount":54,"usageDescription":"","jobId":22,"name":"toString at String.java:2994","description":"Delta: Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys()): Compute snapshot for version: 0","submissionTime":"2023-09-29T20:41:56.274GMT","completionTime":"2023-09-29T20:41:57.192GMT","stageIds":[31,32],"jobGroup":"47","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":1821,"dataRead":2160,"rowCount":8,"usageDescription":"","jobId":20,"name":"toString at String.java:2994","description":"Delta: Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys()): Compute snapshot for version: 0","submissionTime":"2023-09-29T20:41:55.429GMT","completionTime":"2023-09-29T20:41:55.887GMT","stageIds":[27],"jobGroup":"47","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys())","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":18,"name":"","description":"Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys())","submissionTime":"2023-09-29T20:41:54.489GMT","completionTime":"2023-09-29T20:41:54.489GMT","stageIds":[],"jobGroup":"47","status":"SUCCEEDED","numTasks":0,"numActiveTasks":0,"numCompletedTasks":0,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":0,"numActiveStages":0,"numCompletedStages":0,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":12780856,"dataRead":16803097,"rowCount":300000,"usageDescription":"","jobId":13,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys())","submissionTime":"2023-09-29T20:41:41.564GMT","completionTime":"2023-09-29T20:41:54.259GMT","stageIds":[19,18],"jobGroup":"47","status":"SUCCEEDED","numTasks":7,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":6,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":16803097,"dataRead":24823824,"rowCount":300000,"usageDescription":"","jobId":9,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 47:\n# Loop through the schemas dictionary in parallel\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef load_table(table_name):\n    schema = dict_schemas[table_name]\n    get_and_load_tpch_file(file_path, table_name, schema)\n\n\n# Use a ThreadPoolExecutor to run the tasks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    executor.map(load_table, dict_schemas.keys())","submissionTime":"2023-09-29T20:41:36.497GMT","completionTime":"2023-09-29T20:41:41.221GMT","stageIds":[14],"jobGroup":"47","status":"SUCCEEDED","numTasks":6,"numActiveTasks":0,"numCompletedTasks":6,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":6,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"39ca0352-1e47-4cd1-9256-8f8ef44dc248"},"text/plain":"StatementMeta(, e4252176-7253-4989-8af2-efcc9bc414e0, 47, Finished, Available)"},"metadata":{}}],"execution_count":24,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"advisor":{"adviceMetadata":"{\"artifactId\":\"b2901e7b-74e6-4a93-a203-e7d30b5003a3\",\"activityId\":\"e4252176-7253-4989-8af2-efcc9bc414e0\",\"applicationId\":\"application_1696015354941_0001\",\"jobGroupId\":\"47\",\"advices\":{\"info\":2}}"}},"id":"93f48302-69e3-4992-a937-7e95dd38e91c"},{"cell_type":"code","source":["# Report how many CPUs the worker has\n","import os\n","print(os.cpu_count())"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"e4252176-7253-4989-8af2-efcc9bc414e0","statement_id":48,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-29T20:41:20.5469738Z","session_start_time":null,"execution_start_time":"2023-09-29T20:42:21.3980611Z","execution_finish_time":"2023-09-29T20:42:21.6924561Z","spark_jobs":{"numbers":{"FAILED":0,"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"23f6f03e-73ea-45dd-af52-817b4bf12eac"},"text/plain":"StatementMeta(, e4252176-7253-4989-8af2-efcc9bc414e0, 48, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["8\n"]}],"execution_count":25,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"a5e1c603-c802-4f81-b06e-a9b7dd833795"},{"cell_type":"markdown","source":["### Checks\n","Report the rowcounts to confirm how many rows have been loaded into each table"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"0ae856ca-b21e-4e37-88ce-f7f002d870e1"},{"cell_type":"code","source":["%%sql\n","SELECT 'customer' AS source, COUNT(*) AS records FROM customer\n","UNION ALL\n","SELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\n","UNION ALL\n","SELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\n","UNION ALL\n","SELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\n","UNION ALL\n","SELECT 'part\t' AS source, COUNT(*) AS records FROM part\n","UNION ALL\n","SELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\n","UNION ALL\n","SELECT 'region\t' AS source, COUNT(*) AS records FROM region\n","UNION ALL\n","SELECT 'supplier' AS source, COUNT(*) AS records FROM supplier;"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"e4252176-7253-4989-8af2-efcc9bc414e0","statement_id":49,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-29T20:41:20.6199315Z","session_start_time":null,"execution_start_time":"2023-09-29T20:42:22.2233759Z","execution_finish_time":"2023-09-29T20:42:28.4873024Z","spark_jobs":{"numbers":{"FAILED":0,"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":17},"jobs":[{"displayName":"take at SQLInterpreter.scala:133","dataWritten":0,"dataRead":1871,"rowCount":33,"usageDescription":"","jobId":72,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier","submissionTime":"2023-09-29T20:42:27.479GMT","completionTime":"2023-09-29T20:42:27.585GMT","stageIds":[114,115,111,108,112,109,116,113,110],"jobGroup":"49","status":"SUCCEEDED","numTasks":41,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":33,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":8,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"take at SQLInterpreter.scala:133","dataWritten":59,"dataRead":2068,"rowCount":10001,"usageDescription":"","jobId":71,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier","submissionTime":"2023-09-29T20:42:27.074GMT","completionTime":"2023-09-29T20:42:27.282GMT","stageIds":[107],"jobGroup":"49","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"take at SQLInterpreter.scala:133","dataWritten":59,"dataRead":1120,"rowCount":6,"usageDescription":"","jobId":70,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier","submissionTime":"2023-09-29T20:42:26.992GMT","completionTime":"2023-09-29T20:42:27.239GMT","stageIds":[106],"jobGroup":"49","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"take at SQLInterpreter.scala:133","dataWritten":450,"dataRead":13912,"rowCount":800008,"usageDescription":"","jobId":69,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier","submissionTime":"2023-09-29T20:42:26.848GMT","completionTime":"2023-09-29T20:42:27.180GMT","stageIds":[105],"jobGroup":"49","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"take at SQLInterpreter.scala:133","dataWritten":115,"dataRead":4844,"rowCount":200002,"usageDescription":"","jobId":68,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier","submissionTime":"2023-09-29T20:42:26.797GMT","completionTime":"2023-09-29T20:42:27.152GMT","stageIds":[104],"jobGroup":"49","status":"SUCCEEDED","numTasks":2,"numActiveTasks":0,"numCompletedTasks":2,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":2,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"take at SQLInterpreter.scala:133","dataWritten":451,"dataRead":19864,"rowCount":1500008,"usageDescription":"","jobId":67,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier","submissionTime":"2023-09-29T20:42:26.714GMT","completionTime":"2023-09-29T20:42:27.064GMT","stageIds":[103],"jobGroup":"49","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"take at SQLInterpreter.scala:133","dataWritten":59,"dataRead":1357,"rowCount":26,"usageDescription":"","jobId":66,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier","submissionTime":"2023-09-29T20:42:26.621GMT","completionTime":"2023-09-29T20:42:26.967GMT","stageIds":[102],"jobGroup":"49","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"take at SQLInterpreter.scala:133","dataWritten":451,"dataRead":31760,"rowCount":6001223,"usageDescription":"","jobId":65,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier","submissionTime":"2023-09-29T20:42:26.557GMT","completionTime":"2023-09-29T20:42:26.981GMT","stageIds":[101],"jobGroup":"49","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"take at SQLInterpreter.scala:133","dataWritten":227,"dataRead":8340,"rowCount":150004,"usageDescription":"","jobId":64,"name":"take at SQLInterpreter.scala:133","description":"Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier","submissionTime":"2023-09-29T20:42:26.511GMT","completionTime":"2023-09-29T20:42:26.700GMT","stageIds":[100],"jobGroup":"49","status":"SUCCEEDED","numTasks":4,"numActiveTasks":0,"numCompletedTasks":4,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":4,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":2041,"rowCount":3,"usageDescription":"","jobId":63,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier: Filtering files for query","submissionTime":"2023-09-29T20:42:26.284GMT","completionTime":"2023-09-29T20:42:26.397GMT","stageIds":[99,98],"jobGroup":"49","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":1785,"rowCount":3,"usageDescription":"","jobId":62,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier: Filtering files for query","submissionTime":"2023-09-29T20:42:26.054GMT","completionTime":"2023-09-29T20:42:26.180GMT","stageIds":[96,97],"jobGroup":"49","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":1867,"rowCount":3,"usageDescription":"","jobId":61,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier: Filtering files for query","submissionTime":"2023-09-29T20:42:25.823GMT","completionTime":"2023-09-29T20:42:25.937GMT","stageIds":[94,95],"jobGroup":"49","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":2096,"rowCount":3,"usageDescription":"","jobId":60,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier: Filtering files for query","submissionTime":"2023-09-29T20:42:25.605GMT","completionTime":"2023-09-29T20:42:25.716GMT","stageIds":[93,92],"jobGroup":"49","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":2078,"rowCount":3,"usageDescription":"","jobId":59,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier: Filtering files for query","submissionTime":"2023-09-29T20:42:25.383GMT","completionTime":"2023-09-29T20:42:25.498GMT","stageIds":[90,91],"jobGroup":"49","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":1809,"rowCount":3,"usageDescription":"","jobId":58,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier: Filtering files for query","submissionTime":"2023-09-29T20:42:25.103GMT","completionTime":"2023-09-29T20:42:25.246GMT","stageIds":[88,89],"jobGroup":"49","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":2337,"rowCount":3,"usageDescription":"","jobId":57,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier: Filtering files for query","submissionTime":"2023-09-29T20:42:24.862GMT","completionTime":"2023-09-29T20:42:24.977GMT","stageIds":[86,87],"jobGroup":"49","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":2060,"rowCount":3,"usageDescription":"","jobId":56,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 49:\nSELECT 'customer' AS source, COUNT(*) AS records FROM customer\nUNION ALL\nSELECT 'lineitem' AS source, COUNT(*) AS records FROM lineitem\nUNION ALL\nSELECT 'nation\t' AS source, COUNT(*) AS records FROM nation\nUNION ALL\nSELECT 'orders\t' AS source, COUNT(*) AS records FROM orders\nUNION ALL\nSELECT 'part\t' AS source, COUNT(*) AS records FROM part\nUNION ALL\nSELECT 'partsupp' AS source, COUNT(*) AS records FROM partsupp\nUNION ALL\nSELECT 'region\t' AS source, COUNT(*) AS records FROM region\nUNION ALL\nSELECT 'supplier' AS source, COUNT(*) AS records FROM supplier: Filtering files for query","submissionTime":"2023-09-29T20:42:24.643GMT","completionTime":"2023-09-29T20:42:24.755GMT","stageIds":[84,85],"jobGroup":"49","status":"SUCCEEDED","numTasks":51,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":1,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"a4a506e6-0f0d-4f9f-9789-774100b54be6"},"text/plain":"StatementMeta(, e4252176-7253-4989-8af2-efcc9bc414e0, 49, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":26,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[{"name":"source","type":"string","nullable":false,"metadata":{}},{"name":"records","type":"long","nullable":false,"metadata":{}}]},"data":[["customer","150000"],["lineitem","6001215"],["nation\t","25"],["orders\t","1500000"],["part\t","200000"],["partsupp","800000"],["region\t","5"],["supplier","10000"]]},"text/plain":"<Spark SQL result set with 8 rows and 2 fields>"},"metadata":{}}],"execution_count":26,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false,"sqlViewState":{"tableOptions":{},"chartOptions":{"chartType":"column","aggregationType":"sum","categoryFieldKeys":["0"],"seriesFieldKeys":["1"],"isStacked":false,"binsNumber":10,"wordFrequency":"-1"}}},"id":"db17704b-a7bd-4aea-83f2-898b22baed95"},{"cell_type":"code","source":["%%sql\n","SHOW TABLES"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"e4252176-7253-4989-8af2-efcc9bc414e0","statement_id":50,"state":"finished","livy_statement_state":"available","queued_time":"2023-09-29T20:41:20.7333551Z","session_start_time":null,"execution_start_time":"2023-09-29T20:42:28.8947539Z","execution_finish_time":"2023-09-29T20:42:29.6976578Z","spark_jobs":{"numbers":{"FAILED":0,"UNKNOWN":0,"RUNNING":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"e1a553aa-78ce-46ca-ac0a-ccaca553c60f"},"text/plain":"StatementMeta(, e4252176-7253-4989-8af2-efcc9bc414e0, 50, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":27,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[{"name":"namespace","type":"string","nullable":false,"metadata":{}},{"name":"tableName","type":"string","nullable":false,"metadata":{}},{"name":"isTemporary","type":"boolean","nullable":false,"metadata":{}}]},"data":[["lh_tpch1","nation",false],["lh_tpch1","orders",false],["lh_tpch1","lineitem",false],["lh_tpch1","customer",false],["lh_tpch1","part",false],["lh_tpch1","partsupp",false],["lh_tpch1","region",false],["lh_tpch1","supplier",false]]},"text/plain":"<Spark SQL result set with 8 rows and 3 fields>"},"metadata":{}}],"execution_count":27,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"e55cc811-3905-4f45-9749-2872696600c4"}]}